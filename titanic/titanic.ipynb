{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pandas scikit-learn numpy matplotlib torch\n",
    "!kaggle competitions download titanic\n",
    "!unzip -o titanic.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model I: Birkenhead Model\n",
    "\n",
    "To get things going, we can make an easy first pass model that operates on the knowledge that women and children were prioritized evacuation under the [Birkenhead drill](https://en.wikipedia.org/wiki/Women_and_children_first).  Simply put, if you are a woman or under the age of 13, the model will predict that the individual survives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_age = 12.0\n",
    "\n",
    "# Keep sex and age columns\n",
    "reduced = train[[\"Sex\", \"Age\", \"Survived\"]].copy()\n",
    "reduced.Sex = (reduced.Sex == \"female\").astype(int)\n",
    "reduced.Age = (reduced.Age <= child_age).astype(int)\n",
    "reduced[\"predicted\"] = reduced.Sex | reduced.Age\n",
    "train_acc = (reduced.predicted == reduced.Survived).mean()\n",
    "sex_only = (reduced.Sex == reduced.Survived).mean()\n",
    "print(f\"Birkenhead drill train accuracy: {train_acc * 100:.2f}%\")\n",
    "print(f\"Sex only train accuracy: {sex_only * 100:.2f}%\")\n",
    "\n",
    "# Write out the submission\n",
    "bh_test = test[[\"PassengerId\", \"Sex\", \"Age\"]].copy()\n",
    "bh_test.Sex = (bh_test.Sex == \"female\").astype(int)\n",
    "bh_test.Age = (bh_test.Age <= child_age).astype(int)\n",
    "bh_test[\"Survived\"] = bh_test.Sex | bh_test.Age\n",
    "bh_test.to_csv(\"birkenhead.csv\", columns=[\"PassengerId\", \"Survived\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions submit titanic -f birkenhead.csv -m \"Naive Model\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!  For such a simple model we are nearly 80% accurate.  Adjusting for children didn't make much of a difference, but it did give us an extra half a percent or so.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model II: Logistic Regression with Simple Imputation\n",
    "\n",
    "Let's get all datapoints involved by using a simple linear model to classify survival.  We still have to deal with the case where data is missing from some columns, so let's apply the simplest imputation strategy we can derive: modal imputation.  We'll just fill all missing values with the most common value for that column and move on.  This will help establish a baseline for future approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What columns lack entries?\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_data_prep(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    cleaned = data.copy(deep=True)\n",
    "    cleaned.Sex = (cleaned.Sex == \"female\").astype(int)\n",
    "\n",
    "    # Drop complex string fields like name, Cabin, and Ticket\n",
    "    cleaned.drop(columns=[\"Name\", \"Cabin\", \"Ticket\"], inplace=True)\n",
    "\n",
    "    # Impute Age, Embarked\n",
    "    cleaned.Age.fillna(cleaned.Age.median(), inplace=True)\n",
    "    cleaned.Fare.fillna(cleaned.Fare.median(), inplace=True)\n",
    "    cleaned.Embarked.fillna(cleaned.Embarked.mode().iloc[0], inplace=True)\n",
    "\n",
    "    # Get dummy variables for Embarked\n",
    "    cleaned = pd.get_dummies(cleaned, columns=[\"Embarked\"])\n",
    "\n",
    "    # Log fare to get rid of long tails\n",
    "    cleaned.Fare = np.log10(cleaned.Fare + 1)\n",
    "\n",
    "    # Normalize age\n",
    "    cleaned.Age = cleaned.Age / cleaned.Age.max()\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = simple_data_prep(train)\n",
    "test_clean = simple_data_prep(test)\n",
    "train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using logistic regression\n",
    "lgr = LogisticRegression(max_iter=1000, verbose=True)\n",
    "x_cols = [x for x in train_clean.columns if x not in [\"Survived\", \"PassengerId\"]]\n",
    "print(x_cols)\n",
    "lgr.fit(train_clean[x_cols], y=train_clean.Survived)\n",
    "train_acc = np.mean(lgr.predict(train_clean[x_cols]) == train_clean[\"Survived\"]) * 100\n",
    "print(f\"Accuracy = {train_acc:.2f}\")\n",
    "\n",
    "test_clean[\"Survived\"] = lgr.predict(test_clean[x_cols])\n",
    "test_clean[[\"PassengerId\", \"Survived\"]].to_csv(\"simple_lgr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions submit titanic -f simple_lgr.csv -m \"Simple imputation and logistic regression\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better Imputation\n",
    "\n",
    "Before trying out any more sophisticated models, let's try to clean up our data to get the most out of what we have.\n",
    "\n",
    "## Breaking Down String Fields\n",
    "\n",
    "String fields like Cabin, Ticket, Name, and Embarked cannot be inputs to most models at this point and must be parsed into numerical fields.  Fortunately, these fields have lots of rich structure that embed information about the passenger.  This section will deal with breaking information out of these fields into subfields that we can use to impute missing fields and ultimately train a model on.\n",
    "\n",
    "### Passenger Names\n",
    "\n",
    "Fortunately, passenger's names on the ticket reveal quite a bit of information about their status, which is highly correlated to their age.  For example:\n",
    "\n",
    "- \"Master\" is a honorific for young men or boys, meaning the age is likely under 18 years.  \n",
    "- Married women are given \"Mrs\" while unmarried women or girls are \"Miss\"\n",
    "- Some married women have their husbands name in parentheses. Some do not, possibly implying a widow?  Widows tend to be older \n",
    "\n",
    "These features in the name field can be extracted to binary variables which can be used to impute ages.\n",
    "\n",
    "### Tickets\n",
    "\n",
    "Some tickets are simply numbered, but others have letters or other encodings beforehand.  To extract meaningful information from the ticket field, split out any letters, or what we will call \"ticket modifiers\" and numbers, or \"ticket numbers\".  Modifiers will be mapped to an integer encoding with 0 being no characters in front of a ticket number.  Tickets with only letters will have ticket number 0.\n",
    "\n",
    "### Cabin Number\n",
    "\n",
    "The least populated field, cabin number seems to encode a number of things - the deck of the ship, the room number, and possibly the number of cabins this passenger has purchased.  Some cabin entries only have a deck associated with them and some have multiple entries.  We can break this field down into three variables: \n",
    "- An integer encoding for the deck the passenger was assigned to\n",
    "- The cabin number or first cabin number in the first cabin entry\n",
    "- The number of cabin numbers or spaces in the cabin entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which fields have missing entries in both datasets\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_names(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Process passenger names into several columns that represent title information in a categorical\n",
    "    variable\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): A dataframe with column \"Name\"\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with new columns derived from \"Name\"\n",
    "    \"\"\"\n",
    "    modified = data.copy(deep=True)\n",
    "\n",
    "    # Develop columns based on the passenger's name\n",
    "    modified[\"master\"] = (data.Name.str.contains(\"master\", case=False)).astype(int)\n",
    "    modified[\"mrs\"] = (data.Name.str.contains(\"Mrs\", case=True)).astype(int)\n",
    "    modified[\"miss\"] = (data.Name.str.contains(\"Miss\", case=True)).astype(int)\n",
    "    modified[\"widow\"] = (modified[\"mrs\"] & ~data.Name.str.contains(\"\\(\")).astype(int)\n",
    "    modified[\"mr\"] = (data.Name.str.contains(\"Mr.\", case=True)).astype(int)\n",
    "    modified[\"surname\"] = modified.Name.apply(\n",
    "        lambda x: x.split(\" \")[0].replace(\",\", \"\")\n",
    "    )\n",
    "    unique_names = modified.surname.unique()\n",
    "    surname_map = dict(zip(unique_names, range(len(unique_names))))\n",
    "    modified.surname = modified.surname.apply(lambda x: surname_map[x])\n",
    "    modified.drop(columns=[\"Name\"], inplace=True)\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticket_to_number(ticket):\n",
    "    if isinstance(ticket, (int, float)):\n",
    "        return int(ticket)\n",
    "    else:\n",
    "        no_letters = \"\".join(filter(str.isdigit, ticket))\n",
    "        if len(no_letters):\n",
    "            return int(no_letters)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "def process_ticket(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    modified = data.copy(deep=True)\n",
    "    # Develop columns based on the ticket description\n",
    "    ticket_modifiers = {\"\"}\n",
    "    for ticket in data.Ticket.tolist():\n",
    "        # Take only letters, some modifiers vary in capitalization, so lower before adding\n",
    "        # to our set\n",
    "        modifier = \"\".join(filter(str.isalpha, ticket)).lower()\n",
    "        ticket_modifiers.add(modifier)\n",
    "    ticket_modifiers = dict(zip(ticket_modifiers, range(len(ticket_modifiers))))\n",
    "\n",
    "    modified[\"ticket_modifier\"] = modified.Ticket.apply(\n",
    "        lambda x: ticket_modifiers[\"\".join(filter(str.isalpha, x)).lower()]\n",
    "    )\n",
    "    modified[\"ticket_number\"] = modified.Ticket.apply(ticket_to_number)\n",
    "    modified[\"ticket_digits\"] = modified[\"ticket_number\"].apply(lambda x: len(str(x)))\n",
    "    modified.drop(columns=[\"Ticket\"], inplace=True)\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number(cabin_entry):\n",
    "    \"\"\"Extract a cabin number if one exists or take the mean of all numbers found\"\"\"\n",
    "    if isinstance(cabin_entry, (int, float)):\n",
    "        return int(cabin_entry)\n",
    "    else:\n",
    "        entries = cabin_entry.split(\" \")\n",
    "        numbers = [\"\".join(filter(str.isdigit, x)) for x in entries]\n",
    "        numbers = [int(x) for x in numbers if len(x)]\n",
    "        if len(numbers) == 0:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return sum(numbers) / len(numbers)\n",
    "\n",
    "\n",
    "def process_cabin(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    modified = data.copy(deep=True)\n",
    "    # Develop columns based on the cabin\n",
    "    with_cabins = modified[~modified.Cabin.isna()]\n",
    "    modified.loc[~modified.Cabin.isna(), \"cabin_entries\"] = with_cabins.Cabin.apply(\n",
    "        lambda x: len(str(x).split(\" \"))\n",
    "    )\n",
    "\n",
    "    # Develop an encoding for the deck level, leave missing ones as NA\n",
    "    for idx, level in enumerate([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]):\n",
    "        modified.loc[\n",
    "            ~modified.Cabin.isna() & with_cabins.Cabin.str.contains(level, case=False),\n",
    "            \"cabin_level\",\n",
    "        ] = (\n",
    "            idx + 1\n",
    "        )\n",
    "    modified.loc[with_cabins.index, \"cabin_number\"] = with_cabins.Cabin.apply(\n",
    "        get_number\n",
    "    )\n",
    "    modified.drop(columns=[\"Cabin\"], inplace=True)\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string_fields(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    modified = data.copy(deep=True)\n",
    "\n",
    "    # Process Sex to be binary\n",
    "    modified.Sex = (modified.Sex == \"female\").astype(int)\n",
    "    # Get dummy variables for embarked\n",
    "    modified = pd.get_dummies(modified, columns=[\"Embarked\"])\n",
    "    modified = process_names(modified)\n",
    "    modified = process_cabin(modified)\n",
    "    modified = process_ticket(modified)\n",
    "    return modified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation Methods\n",
    "\n",
    "There are many different approaches to imputing missing age and cabin values.  We'll look into two different approaches:\n",
    "\n",
    "1. Manually determining groups of individuals and assigning a value based on their statistical distribution\n",
    "2. Using a nearest-neighbor method to draw conclusions about similarities between individuals and propagating known values\n",
    "\n",
    "Option 1 may be more heavy handed, but will allow us to prioritize assumptions based on name or other string fields to determine age.  Option 2 would be better suited for inferring cabin, where it's less obvious what the value may be, but it's clear what variables may influence the missing quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age_groups(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    modified = data.copy(deep=True)\n",
    "    is_ageless = modified.Age.isna()\n",
    "    male = modified.Sex == 0\n",
    "    # Find masters in the group and impute age\n",
    "    is_master = modified.master == 1\n",
    "    modified.loc[is_ageless & is_master, \"Age\"] = modified.loc[\n",
    "        is_master, \"Age\"\n",
    "    ].median()\n",
    "\n",
    "    # Age for unmarried men (not master title) and women that are part of families\n",
    "    in_family = (modified.Parch > 0) & (modified.SibSp > 0)\n",
    "    is_miss = modified.miss == 1\n",
    "    modified.loc[is_ageless & is_miss & in_family, \"Age\"] = modified.loc[\n",
    "        is_miss & in_family, \"Age\"\n",
    "    ].median()\n",
    "    modified.loc[is_ageless & male & in_family, \"Age\"] = modified.loc[\n",
    "        male & in_family, \"Age\"\n",
    "    ].median()\n",
    "\n",
    "    # Children travelling with a nanny (SibSp == 0, Parch == 0)\n",
    "    with_nanny = (modified.Parch == 0) & (modified.SibSp > 0)\n",
    "    modified.loc[is_ageless & with_nanny, \"Age\"] = modified.loc[\n",
    "        with_nanny, \"Age\"\n",
    "    ].median()\n",
    "\n",
    "    # Age for married women based on widow status\n",
    "    widow = modified.widow == 1\n",
    "    modified.loc[is_ageless & widow, \"Age\"] = modified.loc[widow, \"Age\"].median()\n",
    "\n",
    "    # Married women\n",
    "    married_woman = modified.mrs & ~widow\n",
    "    modified.loc[is_ageless & married_woman, \"Age\"] = modified.loc[\n",
    "        married_woman, \"Age\"\n",
    "    ].median()\n",
    "\n",
    "    # Single men and women (SibSp and Parch is 0).  Treat these two differently as I could imagine younger men probably travelled alone more often\n",
    "    # than younger women\n",
    "    alone = (modified.SibSp == 0) & (modified.Parch == 0)\n",
    "    single_man = (modified.Sex == 0) & alone\n",
    "    single_woman = (modified.Sex == 1) & alone & modified.miss\n",
    "    modified.loc[is_ageless & single_man, \"Age\"] = modified.loc[\n",
    "        single_man, \"Age\"\n",
    "    ].median()\n",
    "    modified.loc[is_ageless & single_woman, \"Age\"] = modified.loc[\n",
    "        single_man, \"Age\"\n",
    "    ].median()\n",
    "\n",
    "    # Married men (Mr. and SibSp > 0 and Parch = 0)\n",
    "    married_men_no_kids = (\n",
    "        (modified.Sex == 0) & (modified.SibSp == 1) & (modified.Parch == 0)\n",
    "    )\n",
    "    modified.loc[is_ageless & married_men_no_kids, \"Age\"] = modified.loc[\n",
    "        married_men_no_kids, \"Age\"\n",
    "    ].median()\n",
    "\n",
    "    # Cover all other conditions\n",
    "    is_still_ageless = modified.Age.isna()\n",
    "    modified.loc[is_still_ageless, \"Age\"] = modified.Age.median()\n",
    "\n",
    "    # Check we've imputed age for all passengers\n",
    "    assert len(modified[modified.Age.isna()]) == 0\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_cabin(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    modified = data.copy(deep=True)\n",
    "    imputer = KNNImputer()\n",
    "    out = imputer.fit_transform(modified)\n",
    "    modified = out\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    modified = data.copy(deep=True)\n",
    "    modified = process_string_fields(modified)\n",
    "    # Impute the fare \n",
    "    modified.Fare.fillna(modified.Fare.mean())\n",
    "    \n",
    "    modified = impute_age_groups(modified)\n",
    "    modified[modified.columns] = impute_cabin(modified)\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    modified = data.copy(deep=True)\n",
    "\n",
    "    # Normalize fair, ticket number by log10\n",
    "    modified.Fare = np.log10(modified.Fare + 1)\n",
    "    modified.ticket_number = np.log10(modified.ticket_number + 1)\n",
    "    # Normalize all columns\n",
    "    for column in modified.columns:\n",
    "        min_max = (modified[column].max() - modified[column].min())\n",
    "        if min_max != 0:\n",
    "            modified[column] = (modified[column] - modified[column].min()) / min_max\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = preprocess(train)\n",
    "test_clean = preprocess(test)\n",
    "\n",
    "train_norm = normalize(train_clean)\n",
    "test_norm = normalize(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train, t_val = train_test_split(train_norm, test_size=.2)\n",
    "classifiers = [LogisticRegression(max_iter=500), SVC()]\n",
    "train_x = t_train[[x for x in t_train.columns if x not in ['Survived', 'PassengerId']]]\n",
    "train_y = t_train['Survived']\n",
    "val_x = t_val[[x for x in t_val.columns if x not in ['Survived', 'PassengerId']]]\n",
    "val_y = t_val['Survived']\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(train_x, train_y)\n",
    "    train_acc = np.mean(classifier.predict(train_x) == train_y) * 100\n",
    "    val_acc = np.mean(classifier.predict(val_x) == val_y) * 100\n",
    "    print(train_acc)\n",
    "    print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [x for x in train_norm.columns if x not in ['Survived', 'PassengerId']]\n",
    "train_x = train_norm[train_cols]\n",
    "train_y = train_norm['Survived']\n",
    "best_classifier = LogisticRegression()\n",
    "\n",
    "best_classifier.fit(train_x, train_y)\n",
    "train_acc = np.mean(best_classifier.predict(train_x) == train_y) * 100\n",
    "print(train_acc)\n",
    "\n",
    "test_x = test_norm[train_cols]\n",
    "test['Survived'] = best_classifier.predict(test_x)\n",
    "test['Survived'] = test['Survived'].astype(int)\n",
    "test[['PassengerId', 'Survived']].to_csv('grouped_age_cabin_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit titanic -f grouped_age_cabin_lr.csv -m \"Age imputation by manually developed groups, cabin imputation, LR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff = pd.read_csv('grouped_age_cabin_lr.csv')\n",
    "    new_stuff.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(new_stuff.Survived == old_stuff.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c5e7bc60812e4f465d8a8f03ded68579c8c0c964eec928bebe0bf95b0baae9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
